{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning DeBERTA\n",
    "In this notebook, we will provide the code for fine-tuning DeBERTA.\n",
    "\n",
    "## Set-up environment\n",
    "\n",
    "First, we install the libraries which we'll use: HuggingFace Transformers and Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict, load_dataset, load_metric\n",
    "import numpy as np\n",
    "import re\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\"MPS not available because the current PyTorch install was not \"\n",
    "              \"built with MPS enabled.\")\n",
    "    else:\n",
    "        print(\"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "              \"and/or you do not have an MPS-enabled device on this machine.\")\n",
    "\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "We will read the three csv files (train, test, validation) and convert them to a HuggingFace Dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose between 'superglue', 'xsum', 'commensense'\n",
    "data = 'superglue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CHOOSE SIZE OF DATA ####\n",
    "# if you just want to try out the code, select a small number\n",
    "testing_only = True\n",
    "num_data_points = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data == 'superglue':\n",
    "    # choose SuperGLUE BoolQ (Yes/No Questions)\n",
    "    superglue_data_path = '../../data/SloveneSuperGLUE/SuperGLUE-GoogleMT/csv/BoolQ'    \n",
    "    # Load your NLP dataset\n",
    "    if testing_only:\n",
    "        train_df = pd.read_csv(f\"{superglue_data_path}/train.csv\")[:num_data_points]\n",
    "        eval_df = pd.read_csv(f\"{superglue_data_path}/val.csv\")[:num_data_points]\n",
    "    else:\n",
    "        train_df = pd.read_csv(f\"{superglue_data_path}/train.csv\")\n",
    "        eval_df = pd.read_csv(f\"{superglue_data_path}/val.csv\")\n",
    "\n",
    "\n",
    "    # Convert data into Hugging Face Dataset format\n",
    "    dataset_train = Dataset.from_pandas(train_df)\n",
    "    dataset_eval = Dataset.from_pandas(eval_df)\n",
    "\n",
    "    # Create a DatasetDict containing the three splits\n",
    "    dataset = DatasetDict({\n",
    "        'train': dataset_train,\n",
    "        'validation': dataset_eval\n",
    "    })\n",
    "elif data == 'commensense':\n",
    "    dataset = load_dataset(\"commonsense_qa\")\n",
    "elif data == 'xsum':\n",
    "    dataset = load_dataset(\"GEM/xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the dataset contains 3 splits: one for training, one for validation and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['idx', 'label', 'passage', 'question'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['idx', 'label', 'passage', 'question'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first example of the training split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'label': True,\n",
       " 'passage': 'Perzijski jezik - perzijščina (/ ˈpɜːrʒən, -ʃən /), znana tudi pod endonimom farsi (فارسی fārsi (fɒːɾˈsiː) (poslušaj)), je eden od zahodnoiranskih jezikov v indoiranski veji indoevropskega jezika družina. Govorijo se predvsem v Iranu, Afganistanu (od 1958 uradno znan kot Dari) in Tadžikistanu (od sovjetske dobe uradno znani kot Tadžiki) ter nekaterih drugih regijah, ki so bile v preteklosti perzijske družbe in so veljale za del Velikega Irana. Zapisano je v perzijski abecedi, spremenjeni različici arabske pisave, ki se je sama razvila iz aramejske abecede.',\n",
       " 'question': 'ali Iran in Afganistan govorita isti jezik'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data\n",
    "\n",
    "As models like BERT don't expect text as direct input, but rather `input_ids`, etc., we tokenize the text using the tokenizer. Here I'm using the `AutoTokenizer` API, which will automatically load the appropriate tokenizer based on the checkpoint on the hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    cleaned_text = text.lower()\n",
    "    \n",
    "    # Remove special characters except whitespace\n",
    "    cleaned_text = re.sub(r'[^\\w\\s]', '', cleaned_text)\n",
    "    \n",
    "    # Remove extra whitespaces\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow the example of [this](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/question_answering.ipynb#scrollTo=oAeoKVaWaIEl) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained tokenizer for deberta\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_on_right = tokenizer.padding_side == \"right\"\n",
    "# The maximum length of a feature (question and context)\n",
    "max_length = 384 \n",
    "# The authorized overlap between two part of the context when splitting it is needed.\n",
    "doc_stride = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Clean questions and passages (or context)\n",
    "    cleaned_questions = [clean_text(q).lstrip() for q in examples[\"question\"]]\n",
    "    cleaned_passages = [clean_text(p) for p in examples[\"passage\"]]\n",
    "\n",
    "    # Tokenize the cleaned inputs\n",
    "    tokenized_examples = tokenizer(\n",
    "        cleaned_questions,\n",
    "        cleaned_passages,\n",
    "        truncation=\"only_second\",  # Assuming passage comes after question\n",
    "        max_length=max_length,\n",
    "        stride=doc_stride,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
    "    # its corresponding example. This key gives us just that.\n",
    "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
    "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
    "    # help us compute the start_positions and end_positions.\n",
    "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
    "\n",
    "    # Let's label those examples!\n",
    "    tokenized_examples[\"labels\"] = []\n",
    "\n",
    "    for i, offsets in enumerate(offset_mapping):\n",
    "        # We will use 1 for True and 0 for False\n",
    "        label = 1 if examples[\"label\"][sample_mapping[i]] == \"True\" else 0\n",
    "        tokenized_examples[\"labels\"].append(label)\n",
    "\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 1563.18 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 4287.08 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Pre-process the train, validation, and test datasets\n",
    "train_dataset = dataset['train'].map(\n",
    "    preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "validation_dataset = dataset['validation'].map(\n",
    "    preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_ids', 'attention_mask', 'labels'])\n"
     ]
    }
   ],
   "source": [
    "example = train_dataset[0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] ali iran in afganistan govorita isti jezik [SEP] perzijski jezik perzijscina [UNK] ʃən znana tudi pod endonimom farsi فارسی farsi fɒːɾˈsiː poslusaj je eden od zahodnoiranskih jezikov v indoiranski veji indoevropskega jezika druzina govorijo se predvsem v iranu afganistanu od 1958 uradno znan kot dari in tadzikistanu od sovjetske dobe uradno znani kot tadziki ter nekaterih drugih regijah ki so bile v preteklosti perzijske druzbe in so veljale za del velikega irana zapisano je v perzijski abecedi spremenjeni razlicici arabske pisave ki se je sama razvila iz aramejske abecede [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(example['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we set the format of our data to PyTorch tensors. This will turn the training, validation and test sets into standard PyTorch [datasets](https://pytorch.org/docs/stable/data.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model\n",
    "\n",
    "Here we define a model that includes a pre-trained base (i.e. the weights from bert-base-uncased) are loaded, with a random initialized classification head (linear layer) on top. One should fine-tune this head, together with the pre-trained base on a labeled dataset.\n",
    "\n",
    "This is also printed by the warning.\n",
    "\n",
    "We set the `problem_type` to be \"multi_label_classification\", as this will make sure the appropriate loss function is used (namely [`BCEWithLogitsLoss`](https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html)). We also make sure the output layer has `len(labels)` output neurons, and we set the id2label and label2id mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
    "\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-squad\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!\n",
    "\n",
    "We are going to train the model using HuggingFace's Trainer API. This requires us to define 2 things:\n",
    "\n",
    "* `TrainingArguments`, which specify training hyperparameters. All options can be found in the [docs](https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments). Below, we for example specify that we want to evaluate after every epoch of training, we would like to save the model every epoch, we set the learning rate, the batch size to use for training/evaluation, how many epochs to train for, and so on.\n",
    "* a `Trainer` object (docs can be found [here](https://huggingface.co/transformers/main_classes/trainer.html#id1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-boolq\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eileen/.pyenv/versions/3.10.0/envs/nlp_env/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 7/21 [00:22<01:06,  4.76s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                              \n",
      "\u001b[A                                     \n",
      "\n",
      " 33%|███▎      | 7/21 [00:24<01:06,  4.76s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3122859597206116, 'eval_runtime': 2.2531, 'eval_samples_per_second': 48.377, 'eval_steps_per_second': 3.107, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 14/21 [00:46<00:19,  2.78s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                               \n",
      "\u001b[A                                     \n",
      "\n",
      " 67%|██████▋   | 14/21 [00:48<00:19,  2.78s/it]\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1253909468650818, 'eval_runtime': 1.9068, 'eval_samples_per_second': 57.164, 'eval_steps_per_second': 3.671, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:58<00:00,  1.35s/it]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "                                               \n",
      "\u001b[A                                     \n",
      "\n",
      "100%|██████████| 21/21 [01:00<00:00,  1.35s/it]\n",
      "\u001b[A\n",
      "                                               \n",
      "100%|██████████| 21/21 [01:00<00:00,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.09127047657966614, 'eval_runtime': 2.2652, 'eval_samples_per_second': 48.12, 'eval_steps_per_second': 3.09, 'epoch': 3.0}\n",
      "{'train_runtime': 60.9586, 'train_samples_per_second': 5.069, 'train_steps_per_second': 0.344, 'train_loss': 0.29338477906726657, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21, training_loss=0.29338477906726657, metrics={'train_runtime': 60.9586, 'train_samples_per_second': 5.069, 'train_steps_per_second': 0.344, 'train_loss': 0.29338477906726657, 'epoch': 3.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model = False\n",
    "\n",
    "if save_model:\n",
    "    trainer.save_model(f\"{model_name}-finetuned-boolq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n",
    "\n",
    "After training, we evaluate our model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:07<00:00,  1.03s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09127047657966614,\n",
       " 'eval_runtime': 7.262,\n",
       " 'eval_samples_per_second': 15.01,\n",
       " 'eval_steps_per_second': 0.964,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Let's test the model on a new sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
