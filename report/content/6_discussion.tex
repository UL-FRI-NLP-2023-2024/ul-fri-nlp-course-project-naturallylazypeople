% Use the Discussion section to objectively evaluate your work, do not just put praise on everything you did, be critical and exposes flaws and weaknesses of your solution. You can also explain what you would do differently if you would be able to start again and what upgrades could be done on the project in the future.

\paragraph{Discussion and issues} In our analysis, we successfully implemented four different PEFT methods and applied them to four different datasets. Unexpectedly, the implementation of the PEFT methods were rather straightforward while the import as well as pre-processing of the datasets posed the real difficulty. All but the BitFit method are implemented through the library \lstinline{peft}. For BitFit, we had to manually specify, that only the bias parameters of the model are to be trained. 

One issue with implementing the pre-processing of the CoNLL-2012 dataset was to handle the special token representing an "empty" label for a token. In the beginning we labelled an empty class with the value of -100 for the delimiters, padding and tokens without corresponding coreference, this caused an assertion failure in the CUDA code which proved to be very difficult to debug. In the end we replaced -100 by introducing an additional class in the classifier and assigning this class to all the special tokens. We also had problems with soft prompt trainer with CommonsenseQA and SST5 datasets, here the issue was kernel length mismatch we did not manage to fix this issue so we did not evaluate soft prompt trainer on this two datasets. The last issue that we faced was the resource availability on the cluster, as we do not own any GPUs we had to test everything on the cluster and that made debugging much harder since we had to first wait to acquire resources and only then we could see the results, which made our development cycle quite slow.

\paragraph{Future directions} As an improvement for the future we would do more thorough hyperparameter search for even more robust results. Another thing could be to resolve issues with soft prompt finetuning for some of the datasets/models.