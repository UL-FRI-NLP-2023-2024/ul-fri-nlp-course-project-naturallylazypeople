PEFT methods can be grouped into five main categories. Additive fine-tuning introduces new trainable parameters for task-specific adaptation, including adapter-based fine-tuning, soft prompt-based fine-tuning, and others. Partial fine-tuning reduces the number of fine-tuned parameters by focusing on critical pre-trained parameters, with methods like bias update, pretrained weight masking, and delta weight masking. Reparameterized fine-tuning utilizes low-rank transformation to decrease trainable parameters, through techniques like low-rank decomposition and LoRA derivatives. Hybrid fine-tuning combines multiple PEFT approaches to leverage strengths and mitigate weaknesses, either manually or automatically. Unified fine-tuning provides streamlined frameworks for incorporating diverse fine-tuning methods into cohesive architectures, emphasizing consistency and efficiency across model adaptation without combining multiple methods.

In this analysis, we will focus on three of these methods:

\input{content/3_1_methods_eileen}
\input{content/3_2_methods_ondra}
\input{content/3_3_methods_andrej}