Since the introduction of attention \cite{vaswani2017attention}, using large language models (LLMs) such as BERT \cite{devlin2019bert} and GPT \cite{radford2018gpt} has become inevitable to various applications across natural language processing (NLP) domains. However, achieving optimal performance often requires fine-tuning these models to specific tasks or datasets. Traditional full fine-tuning methods typically involve updating a large number of parameters, which can be computationally expensive and resource-intensive. Addressing this challenge, parameter-efficient fine-tuning (PEFT) methods have been introduced as a promising approach to optimizing neural networks with fewer parameters \cite{xu2023parameterefficient}. PEFT is characterized by its ability to achieve comparable performance to conventional full fine-tuning methods while training significantly fewer parameters. This reduction not only leads to computational savings but also helps reduce the risk of overfitting, particularly in scenarios with limited data.

This research paper focuses on presenting and comparing various PEFT methods in the context of optimizing natural language processing tasks. Through empirical experiments, we aim at exploring the effectiveness of different PEFT approaches in achieving desirable trade-offs between model complexity, computational efficiency, and task performance.

\noindent Similarly to the work done in \cite{xu2023parameterefficient}, we begin our research by reviewing and categorizing popular PEFT methods. We continue by presenting and discussing the theoretical foundations of three specific methodologies, i.e. low rank adaptation (LoRA) \cite{hu2021lora}, soft prompt-based fine-tuning \cite{lester2021power} and partial fine-tuning \cite{zaken2022bitfit}, and applying these to five different datasets that cover various natural language understanding skills. Lastly, the fine-tuned models will be evaluated based on appropriate performance metrics, computational resources required, and ease of adaptation to different tasks. Through this exploration, we aim at facilitating more resource-conscious approaches to model optimization, accelerating progress in the field of NLP and its applications.