%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% FRI Data Science_report LaTeX Template
% Version 1.0 (28/1/2020)
% 
% Jure Demšar (jure.demsar@fri.uni-lj.si)
%
% Based on MicromouseSymp article template by:
% Mathias Legrand (legrand.mathias@gmail.com) 
% With extensive modifications by:
% Antonio Valente (antonio.luis.valente@gmail.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------
\documentclass[fleqn,moreauthors,10pt]{ds_report}
\usepackage[english]{babel}
\usepackage{xcolor}
\usepackage{tabularx}
\usepackage{listings}

\graphicspath{{fig/}}


\newcommand{\todo}[1]{\textcolor{red}{\textbf{#1}}}

%----------------------------------------------------------------------------------------
%	ARTICLE INFORMATION
%----------------------------------------------------------------------------------------

% Header
\JournalInfo{FRI Natural language processing course 2024}

% Interim or final report
\Archive{Project report} 
%\Archive{Final report} 

% Article title
\PaperTitle{Parameter-Efficient Fine-Tuning of Large Language Models} 

% Authors (student competitors) and their info
\Authors{Ondřej Komín, Andrej Sušnik, Eileen Vu}

% Advisors
\affiliation{\textit{Advisors: Slavko Žitnik}}

% Keywords
\Keywords{Keyword1, Keyword2, Keyword3 ...}
\newcommand{\keywordname}{Keywords}


%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\Abstract{This is the abstract}

%----------------------------------------------------------------------------------------

\begin{document}

% Makes all text pages the same height
\flushbottom 

% Print the title and abstract box
\maketitle 

% Removes page numbering from the first page
\thispagestyle{empty} 

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------
\section*{Introduction}
\input{content/1_intro}
%------------------------------------------------
\section*{Related Work}
\input{content/2_relatedwork}
%------------------------------------------------
\section*{Methods}
\input{content/3_0_methods}
%------------------------------------------------
% \section*{Model}
% Recommendation by Tutor: multilingual DeBERTA v3, sloBERTA, BERTIC (all Balkan languages), CROSLOBERTA
% Baseline: normal fine-tuning
% q Lora (half of the bits than LORA)

% other benchmarks: XGLUE (but our benchmarks should be fine)

% adapters
% - have one NN
% - have multiple adapters for each task
% - is implemented already

% next steps:
% - take slvoenian dataset
% - choose model
% - implement fine-tuning
% - use libraries if available

% until next time:
% - have three methods and finetuning impelemnted
% - for slovenian dataset
% %------------------------------------------------
\section*{Training Pipeline}
\input{content/4_training_pipeline}
%------------------------------------------------
\section*{Environment and reproducibility}
\input{content/4_2_envionment_and_reproducibility}
%------------------------------------------------
\section*{Results}
\input{content/5_0_results}
%------------------------------------------------
\section*{Future directions, ideas}
\input{content/7_future_directions}
%------------------------------------------------
\section*{Discussion}
\input{content/6_discussion}
%------------------------------------------------
% \section*{Backup}
% \input{content/backup}
%----------------------------------------------------------------------------------------
%	REFERENCE LIST
%----------------------------------------------------------------------------------------
\bibliographystyle{unsrt}
\bibliography{report}

\end{document}